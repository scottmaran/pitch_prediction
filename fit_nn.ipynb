{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_name = \"nn_single_model\"\n",
    "DIRECTORY_PATH = f\"models/{model_path_name}\"\n",
    "MODEL_INFO_FILEPATH = f\"{DIRECTORY_PATH}/info.txt\"\n",
    "\n",
    "if not os.path.exists(DIRECTORY_PATH):\n",
    "    os.makedirs(DIRECTORY_PATH)\n",
    "with open(MODEL_INFO_FILEPATH, \"w\") as text_file:\n",
    "    print(f\"##### MODEL INFO #####\", file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device = mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(f\"Using device = {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(\"data/advanced_dataset_final.pkl\")\n",
    "dataset.top = dataset.top.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dummied = pd.get_dummies(dataset, columns=['inning', 'p_throws', 'bases_state', 'stand', 'prev_pitch_type', 'prev_type'], dummy_na=False, drop_first=True)\n",
    "cols_with_nan = dataset_dummied.columns[dataset_dummied.isna().any()].tolist()\n",
    "# Iterate over the columns that have NaN values\n",
    "for col in cols_with_nan:\n",
    "    # Create a new column with the column name appended with '_nan'\n",
    "    new_col_name = col + '_is_nan'\n",
    "    # Create the new column by checking if the values in the original column are NaN\n",
    "    dataset_dummied[new_col_name] = dataset_dummied[col].isna().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dummied.fillna(-99, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dummied.to_pickle(\"data/dummy_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'FF' : 0,\n",
    "           'SL': 1, \n",
    "           'CU': 2, \n",
    "           'SI': 3, \n",
    "           'FC': 4, \n",
    "           'FT': 5, \n",
    "           'KC': 6, \n",
    "           'CH': 7, \n",
    "           'KN': 8, \n",
    "           'FS': 9, \n",
    "           'FO': 10, \n",
    "           'EP': 11, \n",
    "           'SC': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index_stop = 569484 # this is the first index of a new pitcher\n",
    "val_index_stop = 640690 # make sure no overlapping plays\n",
    "\n",
    "training_set = dataset_dummied.iloc[0:train_index_stop, :]\n",
    "validation_set = dataset_dummied.iloc[train_index_stop:val_index_stop, :]\n",
    "test_set = dataset_dummied.iloc[val_index_stop:,]\n",
    "\n",
    "train_X = torch.tensor(training_set.drop([\"uid\", \"pitch_type\", \"type_confidence\", \"pitcher_id\"],axis=1).values.astype(float)).float()\n",
    "train_y = training_set['pitch_type']\n",
    "train_weights = torch.tensor(training_set['type_confidence'].values.astype(np.float32))\n",
    "\n",
    "val_X = torch.tensor(validation_set.drop([\"uid\", \"pitch_type\", \"type_confidence\", \"pitcher_id\"],axis=1).values.astype(float)).float()\n",
    "val_y = validation_set['pitch_type']\n",
    "val_weights = torch.tensor(validation_set['type_confidence'].values.astype(np.float32))\n",
    "\n",
    "test_X = torch.tensor(test_set.drop([\"uid\", \"pitch_type\", \"type_confidence\", \"pitcher_id\"],axis=1).values.astype(float)).float()\n",
    "test_y = test_set['pitch_type']\n",
    "test_weights = torch.tensor(test_set['type_confidence'].values.astype(np.float32))\n",
    "\n",
    "train_y = torch.tensor(train_y.map(mapping).values.astype(np.float32)).type(torch.LongTensor)\n",
    "val_y = torch.tensor(val_y.map(mapping).values.astype(np.float32)).type(torch.LongTensor)\n",
    "test_y = torch.tensor(test_y.map(mapping).values.astype(np.float32)).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 256,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "training_dataset = CustomDataset(train_X, train_y)\n",
    "training_generator = torch.utils.data.DataLoader(training_dataset, **params)\n",
    "validation_dataset = CustomDataset(val_X, val_y)\n",
    "validation_generator = torch.utils.data.DataLoader(validation_dataset, **params)\n",
    "test_dataset = CustomDataset(test_X, test_y)\n",
    "test_generator = torch.utils.data.DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchModel(nn.Module):\n",
    "    def __init__(self, num_outputs=13, feature_input_size=217):\n",
    "        super(PitchModel, self).__init__()\n",
    "\n",
    "        self.feature_input_size = feature_input_size\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "        self.fc1 = nn.Linear(self.feature_input_size, 2000)\n",
    "        self.fc2 = nn.Linear(2000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 300)\n",
    "        self.fc4 = nn.Linear(300, self.num_outputs)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.relu(self.fc1(x))\n",
    "        out2 = self.relu(self.fc2(out1))\n",
    "        out3 = self.relu(self.fc3(out2))\n",
    "        logits = self.fc4(out3)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(loss_history, dataloader, optimizer, model, loss_fn):\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "\n",
    "    for i, (batch_X, batch_y) in enumerate(dataloader):\n",
    "        # Every data instance is an input + label pair\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(batch_X)\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        loss_history.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "        if i % 750 == 0:\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total = batch_y.size(0)\n",
    "            correct = (predicted == batch_y).sum().item()\n",
    "\n",
    "            last_loss = running_loss / 750 # loss per batch\n",
    "            print(f\" batch {i}: loss = {last_loss}, Acc% = {correct/total}\")\n",
    "            running_loss = 0\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, train_loss_hist, val_loss_hist, model, optimizer, criterion, train_gen, val_gen):\n",
    "\n",
    "    for e in range(epochs):\n",
    "        print(f\"######## Epoch {e}: ############\")\n",
    "        model.train(True)\n",
    "        last_train_batch_loss = train_one_epoch(train_loss_hist, train_gen, optimizer, model, criterion)\n",
    "\n",
    "        model.eval()\n",
    "        running_val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_idx, (batch_X, batch_y) in enumerate(val_gen):\n",
    "            with torch.no_grad():\n",
    "                pred_y = model(batch_X)\n",
    "\n",
    "                _, predicted = torch.max(pred_y, 1)\n",
    "                total += batch_y.size(0)\n",
    "                correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "                val_batch_loss = criterion(pred_y, batch_y)\n",
    "                running_val_loss += val_batch_loss\n",
    "                val_loss_hist.append(val_batch_loss.item())\n",
    "        avg_val_loss = running_val_loss/len(val_gen)\n",
    "        val_accuracy = correct/total\n",
    "        print(f'Last train (avg batch) loss = {last_train_batch_loss}, Avg Val Loss = {avg_val_loss}, Val Acc% = {val_accuracy}')\n",
    "\n",
    "    return train_loss_hist, val_loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(dataloader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for x,y in dataloader:\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(x)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 3e-4\n",
    "NUM_EPOCHS = 150\n",
    "model = PitchModel(num_outputs=13, feature_input_size=217)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=3e-4)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "train_loss_hist = []\n",
    "val_loss_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Epoch 0: ############\n",
      " batch 0: loss = 0.011702999114990235, Acc% = 0.09375\n",
      " batch 750: loss = 2.143083478609721, Acc% = 0.3359375\n",
      " batch 1500: loss = 1.7643412246704102, Acc% = 0.36328125\n",
      "Last train (avg batch) loss = 1.7643412246704102, Avg Val Loss = 1.5378103256225586, Val Acc% = 0.4596522764935539\n",
      "######## Epoch 1: ############\n",
      " batch 0: loss = 0.002052007516225179, Acc% = 0.41796875\n",
      " batch 750: loss = 1.553697543303172, Acc% = 0.42578125\n",
      " batch 1500: loss = 1.5076957046190897, Acc% = 0.53125\n",
      "Last train (avg batch) loss = 1.5076957046190897, Avg Val Loss = 1.4741963148117065, Val Acc% = 0.46840153919613514\n",
      "######## Epoch 2: ############\n",
      " batch 0: loss = 0.001963520685831706, Acc% = 0.46875\n",
      " batch 750: loss = 1.4610898626645406, Acc% = 0.4921875\n",
      " batch 1500: loss = 1.4387768972714743, Acc% = 0.484375\n",
      "Last train (avg batch) loss = 1.4387768972714743, Avg Val Loss = 1.3806734085083008, Val Acc% = 0.4769541892537146\n",
      "######## Epoch 3: ############\n",
      " batch 0: loss = 0.0019794079462687173, Acc% = 0.44921875\n",
      " batch 750: loss = 1.3877718334197997, Acc% = 0.51953125\n",
      " batch 1500: loss = 1.36721688858668, Acc% = 0.46484375\n",
      "Last train (avg batch) loss = 1.36721688858668, Avg Val Loss = 1.337931513786316, Val Acc% = 0.48018425413588744\n",
      "######## Epoch 4: ############\n",
      " batch 0: loss = 0.0018340234756469727, Acc% = 0.45703125\n",
      " batch 750: loss = 1.3208934416770934, Acc% = 0.453125\n",
      " batch 1500: loss = 1.3101653637886048, Acc% = 0.47265625\n",
      "Last train (avg batch) loss = 1.3101653637886048, Avg Val Loss = 1.2809513807296753, Val Acc% = 0.4827683060416257\n",
      "######## Epoch 5: ############\n",
      " batch 0: loss = 0.0015928484598795572, Acc% = 0.49609375\n",
      " batch 750: loss = 1.2875284832318623, Acc% = 0.5\n",
      " batch 1500: loss = 1.2828795034090679, Acc% = 0.48046875\n",
      "Last train (avg batch) loss = 1.2828795034090679, Avg Val Loss = 1.2611100673675537, Val Acc% = 0.48254360587590933\n",
      "######## Epoch 6: ############\n",
      " batch 0: loss = 0.0017186678250630696, Acc% = 0.4921875\n",
      " batch 750: loss = 1.2711724762916565, Acc% = 0.46875\n",
      " batch 1500: loss = 1.267640202522278, Acc% = 0.50390625\n",
      "Last train (avg batch) loss = 1.267640202522278, Avg Val Loss = 1.2539825439453125, Val Acc% = 0.48494508889700305\n",
      "######## Epoch 7: ############\n",
      " batch 0: loss = 0.0015813045501708984, Acc% = 0.53125\n",
      " batch 750: loss = 1.2538878129323323, Acc% = 0.5234375\n",
      " batch 1500: loss = 1.2573508688608805, Acc% = 0.46484375\n",
      "Last train (avg batch) loss = 1.2573508688608805, Avg Val Loss = 1.2477229833602905, Val Acc% = 0.4866022526191613\n",
      "######## Epoch 8: ############\n",
      " batch 0: loss = 0.0017768855094909667, Acc% = 0.453125\n",
      " batch 750: loss = 1.2500597999890646, Acc% = 0.52734375\n",
      " batch 1500: loss = 1.2499582454363505, Acc% = 0.4609375\n",
      "Last train (avg batch) loss = 1.2499582454363505, Avg Val Loss = 1.2387173175811768, Val Acc% = 0.48800662865488864\n",
      "######## Epoch 9: ############\n",
      " batch 0: loss = 0.001738581657409668, Acc% = 0.4921875\n",
      " batch 750: loss = 1.2400389706293742, Acc% = 0.484375\n",
      " batch 1500: loss = 1.2430344511667888, Acc% = 0.50390625\n",
      "Last train (avg batch) loss = 1.2430344511667888, Avg Val Loss = 1.228824496269226, Val Acc% = 0.4895514422941887\n",
      "######## Epoch 10: ############\n",
      " batch 0: loss = 0.0017245484987894694, Acc% = 0.45703125\n",
      " batch 750: loss = 1.236086564064026, Acc% = 0.5078125\n",
      " batch 1500: loss = 1.2375200063387553, Acc% = 0.51171875\n",
      "Last train (avg batch) loss = 1.2375200063387553, Avg Val Loss = 1.2395721673965454, Val Acc% = 0.48848411650703594\n",
      "######## Epoch 11: ############\n",
      " batch 0: loss = 0.00180088742574056, Acc% = 0.4140625\n",
      " batch 750: loss = 1.233007181008657, Acc% = 0.4921875\n",
      " batch 1500: loss = 1.2282478213310242, Acc% = 0.5078125\n",
      "Last train (avg batch) loss = 1.2282478213310242, Avg Val Loss = 1.2358826398849487, Val Acc% = 0.4867988652641631\n",
      "######## Epoch 12: ############\n",
      " batch 0: loss = 0.0017145190238952637, Acc% = 0.44140625\n",
      " batch 750: loss = 1.2274032793045044, Acc% = 0.51953125\n",
      " batch 1500: loss = 1.2246691478093465, Acc% = 0.515625\n",
      "Last train (avg batch) loss = 1.2246691478093465, Avg Val Loss = 1.2319799661636353, Val Acc% = 0.4892986546077578\n",
      "######## Epoch 13: ############\n",
      " batch 0: loss = 0.0016101112365722657, Acc% = 0.46484375\n",
      " batch 750: loss = 1.2223220512072246, Acc% = 0.48046875\n",
      " batch 1500: loss = 1.2226694091161092, Acc% = 0.48828125\n",
      "Last train (avg batch) loss = 1.2226694091161092, Avg Val Loss = 1.2453726530075073, Val Acc% = 0.48841389770524957\n",
      "######## Epoch 14: ############\n",
      " batch 0: loss = 0.0015481014251708983, Acc% = 0.49609375\n",
      " batch 750: loss = 1.2171873388290406, Acc% = 0.5\n",
      " batch 1500: loss = 1.2179590856234233, Acc% = 0.48828125\n",
      "Last train (avg batch) loss = 1.2179590856234233, Avg Val Loss = 1.224379539489746, Val Acc% = 0.4922478442827852\n",
      "######## Epoch 15: ############\n",
      " batch 0: loss = 0.001546817143758138, Acc% = 0.53515625\n",
      " batch 750: loss = 1.2149242612520854, Acc% = 0.5078125\n",
      " batch 1500: loss = 1.214082130908966, Acc% = 0.53125\n",
      "Last train (avg batch) loss = 1.214082130908966, Avg Val Loss = 1.2221148014068604, Val Acc% = 0.49309046990422156\n",
      "######## Epoch 16: ############\n",
      " batch 0: loss = 0.0015496430397033691, Acc% = 0.49609375\n",
      " batch 750: loss = 1.2099761258761088, Acc% = 0.4765625\n",
      " batch 1500: loss = 1.2113437717755635, Acc% = 0.41796875\n",
      "Last train (avg batch) loss = 1.2113437717755635, Avg Val Loss = 1.244249939918518, Val Acc% = 0.4795241973990956\n",
      "######## Epoch 17: ############\n",
      " batch 0: loss = 0.0016128977139790853, Acc% = 0.484375\n",
      " batch 750: loss = 1.206963796933492, Acc% = 0.50390625\n",
      " batch 1500: loss = 1.2095361008644103, Acc% = 0.48046875\n",
      "Last train (avg batch) loss = 1.2095361008644103, Avg Val Loss = 1.208748459815979, Val Acc% = 0.4920652753981406\n",
      "######## Epoch 18: ############\n",
      " batch 0: loss = 0.0015496501922607421, Acc% = 0.51171875\n",
      " batch 750: loss = 1.2053726326624552, Acc% = 0.50390625\n",
      " batch 1500: loss = 1.2075174730618794, Acc% = 0.53515625\n",
      "Last train (avg batch) loss = 1.2075174730618794, Avg Val Loss = 1.2189077138900757, Val Acc% = 0.49162991882706514\n",
      "######## Epoch 19: ############\n",
      " batch 0: loss = 0.0015614997545878092, Acc% = 0.50390625\n",
      " batch 750: loss = 1.2023396989504496, Acc% = 0.47265625\n",
      " batch 1500: loss = 1.201075995763143, Acc% = 0.51953125\n",
      "Last train (avg batch) loss = 1.201075995763143, Avg Val Loss = 1.2139289379119873, Val Acc% = 0.4934134763924388\n",
      "######## Epoch 20: ############\n",
      " batch 0: loss = 0.0015763866106669109, Acc% = 0.53125\n",
      " batch 750: loss = 1.1962733669281005, Acc% = 0.51171875\n",
      " batch 1500: loss = 1.2035730776786804, Acc% = 0.55078125\n",
      "Last train (avg batch) loss = 1.2035730776786804, Avg Val Loss = 1.238202691078186, Val Acc% = 0.4839479819116367\n",
      "######## Epoch 21: ############\n",
      " batch 0: loss = 0.001682766596476237, Acc% = 0.4765625\n",
      " batch 750: loss = 1.197881352742513, Acc% = 0.52734375\n",
      " batch 1500: loss = 1.1987320238749186, Acc% = 0.48046875\n",
      "Last train (avg batch) loss = 1.1987320238749186, Avg Val Loss = 1.215829610824585, Val Acc% = 0.49316068870600793\n",
      "######## Epoch 22: ############\n",
      " batch 0: loss = 0.0014679892857869467, Acc% = 0.54296875\n",
      " batch 750: loss = 1.1977133094469705, Acc% = 0.49609375\n",
      " batch 1500: loss = 1.1961817857424417, Acc% = 0.48828125\n",
      "Last train (avg batch) loss = 1.1961817857424417, Avg Val Loss = 1.2151752710342407, Val Acc% = 0.4920793191584979\n",
      "######## Epoch 23: ############\n",
      " batch 0: loss = 0.001579403559366862, Acc% = 0.49609375\n",
      " batch 750: loss = 1.1940453163782756, Acc% = 0.49609375\n",
      " batch 1500: loss = 1.1937808586756389, Acc% = 0.46484375\n",
      "Last train (avg batch) loss = 1.1937808586756389, Avg Val Loss = 1.2155120372772217, Val Acc% = 0.4912928685784906\n",
      "######## Epoch 24: ############\n",
      " batch 0: loss = 0.0015255381266276041, Acc% = 0.51171875\n",
      " batch 750: loss = 1.191293659845988, Acc% = 0.4921875\n",
      " batch 1500: loss = 1.1926661796569824, Acc% = 0.546875\n",
      "Last train (avg batch) loss = 1.1926661796569824, Avg Val Loss = 1.203458547592163, Val Acc% = 0.49639075358818074\n",
      "######## Epoch 25: ############\n",
      " batch 0: loss = 0.0015550201733907064, Acc% = 0.515625\n",
      " batch 750: loss = 1.187610570112864, Acc% = 0.4765625\n",
      " batch 1500: loss = 1.191801506837209, Acc% = 0.5\n",
      "Last train (avg batch) loss = 1.191801506837209, Avg Val Loss = 1.2236268520355225, Val Acc% = 0.49077324944527145\n",
      "######## Epoch 26: ############\n",
      " batch 0: loss = 0.0016433919270833334, Acc% = 0.48828125\n",
      " batch 750: loss = 1.1858419785499572, Acc% = 0.55078125\n",
      " batch 1500: loss = 1.1897252163887024, Acc% = 0.53125\n",
      "Last train (avg batch) loss = 1.1897252163887024, Avg Val Loss = 1.2205564975738525, Val Acc% = 0.49460719602280706\n",
      "######## Epoch 27: ############\n",
      " batch 0: loss = 0.0017190562884012858, Acc% = 0.4609375\n",
      " batch 750: loss = 1.185617747783661, Acc% = 0.51171875\n",
      " batch 1500: loss = 1.1871534695625305, Acc% = 0.51171875\n",
      "Last train (avg batch) loss = 1.1871534695625305, Avg Val Loss = 1.2102712392807007, Val Acc% = 0.49408757688958793\n",
      "######## Epoch 28: ############\n",
      " batch 0: loss = 0.0015582005182902018, Acc% = 0.4921875\n",
      " batch 750: loss = 1.1840523889859518, Acc% = 0.5390625\n",
      " batch 1500: loss = 1.1875759863853455, Acc% = 0.5390625\n",
      "Last train (avg batch) loss = 1.1875759863853455, Avg Val Loss = 1.2218683958053589, Val Acc% = 0.49209336291885514\n",
      "######## Epoch 29: ############\n",
      " batch 0: loss = 0.0017121920585632324, Acc% = 0.48046875\n",
      " batch 750: loss = 1.183519023100535, Acc% = 0.515625\n",
      " batch 1500: loss = 1.1864040972391765, Acc% = 0.44921875\n",
      "Last train (avg batch) loss = 1.1864040972391765, Avg Val Loss = 1.2101483345031738, Val Acc% = 0.4932309075077943\n",
      "######## Epoch 30: ############\n",
      " batch 0: loss = 0.0016794114112854005, Acc% = 0.43359375\n",
      " batch 750: loss = 1.1801538804372151, Acc% = 0.55078125\n",
      " batch 1500: loss = 1.1847392921447755, Acc% = 0.4921875\n",
      "Last train (avg batch) loss = 1.1847392921447755, Avg Val Loss = 1.2105485200881958, Val Acc% = 0.49356795775636886\n",
      "######## Epoch 31: ############\n",
      " batch 0: loss = 0.0016693571408589682, Acc% = 0.4609375\n",
      " batch 750: loss = 1.1819447304407755, Acc% = 0.48046875\n",
      " batch 1500: loss = 1.1793028701146444, Acc% = 0.5\n",
      "Last train (avg batch) loss = 1.1793028701146444, Avg Val Loss = 1.209470272064209, Val Acc% = 0.4945369772210207\n",
      "######## Epoch 32: ############\n",
      " batch 0: loss = 0.001669709841410319, Acc% = 0.4375\n",
      " batch 750: loss = 1.1756048703193664, Acc% = 0.48828125\n",
      " batch 1500: loss = 1.1794212075869241, Acc% = 0.46875\n",
      "Last train (avg batch) loss = 1.1794212075869241, Avg Val Loss = 1.2083507776260376, Val Acc% = 0.49481785242816617\n",
      "######## Epoch 33: ############\n",
      " batch 0: loss = 0.0015262951850891114, Acc% = 0.4921875\n",
      " batch 750: loss = 1.1785831022262574, Acc% = 0.5234375\n",
      " batch 1500: loss = 1.1761819996833802, Acc% = 0.54296875\n",
      "Last train (avg batch) loss = 1.1761819996833802, Avg Val Loss = 1.2069687843322754, Val Acc% = 0.49612392214139256\n",
      "######## Epoch 34: ############\n",
      " batch 0: loss = 0.0015188148816426595, Acc% = 0.53125\n",
      " batch 750: loss = 1.1755662808418275, Acc% = 0.47265625\n",
      " batch 1500: loss = 1.176389407157898, Acc% = 0.51171875\n",
      "Last train (avg batch) loss = 1.176389407157898, Avg Val Loss = 1.2071928977966309, Val Acc% = 0.4940735331292307\n",
      "######## Epoch 35: ############\n",
      " batch 0: loss = 0.0015049912134806314, Acc% = 0.515625\n",
      " batch 750: loss = 1.1718825682004292, Acc% = 0.484375\n",
      " batch 1500: loss = 1.176397509733836, Acc% = 0.4375\n",
      "Last train (avg batch) loss = 1.176397509733836, Avg Val Loss = 1.2282592058181763, Val Acc% = 0.4900570176670505\n",
      "######## Epoch 36: ############\n",
      " batch 0: loss = 0.0017208863894144695, Acc% = 0.484375\n",
      " batch 750: loss = 1.175520351568858, Acc% = 0.51953125\n",
      " batch 1500: loss = 1.1761397145589192, Acc% = 0.5546875\n",
      "Last train (avg batch) loss = 1.1761397145589192, Avg Val Loss = 1.2122600078582764, Val Acc% = 0.4959975282981771\n",
      "######## Epoch 37: ############\n",
      " batch 0: loss = 0.001506837844848633, Acc% = 0.49609375\n",
      " batch 750: loss = 1.171100550810496, Acc% = 0.5546875\n",
      " batch 1500: loss = 1.1719029437700907, Acc% = 0.546875\n",
      "Last train (avg batch) loss = 1.1719029437700907, Avg Val Loss = 1.2057567834854126, Val Acc% = 0.49525320899924163\n",
      "######## Epoch 38: ############\n",
      " batch 0: loss = 0.001484451134999593, Acc% = 0.59375\n",
      " batch 750: loss = 1.1721951112747193, Acc% = 0.5234375\n",
      " batch 1500: loss = 1.1718166187604269, Acc% = 0.4375\n",
      "Last train (avg batch) loss = 1.1718166187604269, Avg Val Loss = 1.2123764753341675, Val Acc% = 0.4915877875459933\n",
      "######## Epoch 39: ############\n",
      " batch 0: loss = 0.0014987185796101888, Acc% = 0.54296875\n",
      " batch 750: loss = 1.1684992966651917, Acc% = 0.5\n",
      " batch 1500: loss = 1.1684780828158061, Acc% = 0.4921875\n",
      "Last train (avg batch) loss = 1.1684780828158061, Avg Val Loss = 1.2044475078582764, Val Acc% = 0.49500042131281075\n",
      "######## Epoch 40: ############\n",
      " batch 0: loss = 0.0015414037704467773, Acc% = 0.515625\n",
      " batch 750: loss = 1.168540048678716, Acc% = 0.51171875\n",
      " batch 1500: loss = 1.1688053108056387, Acc% = 0.515625\n",
      "Last train (avg batch) loss = 1.1688053108056387, Avg Val Loss = 1.2125680446624756, Val Acc% = 0.4902536303120524\n",
      "######## Epoch 41: ############\n",
      " batch 0: loss = 0.0015436669985453289, Acc% = 0.5546875\n",
      " batch 750: loss = 1.1633745794296264, Acc% = 0.5\n",
      " batch 1500: loss = 1.1689548869132995, Acc% = 0.51953125\n",
      "Last train (avg batch) loss = 1.1689548869132995, Avg Val Loss = 1.210301160812378, Val Acc% = 0.4937926579220852\n",
      "######## Epoch 42: ############\n",
      " batch 0: loss = 0.001528558095296224, Acc% = 0.55078125\n",
      " batch 750: loss = 1.1664766112963358, Acc% = 0.5078125\n",
      " batch 1500: loss = 1.1666209084192911, Acc% = 0.5859375\n",
      "Last train (avg batch) loss = 1.1666209084192911, Avg Val Loss = 1.223569393157959, Val Acc% = 0.48993062382383507\n",
      "######## Epoch 43: ############\n",
      " batch 0: loss = 0.0017058766682942709, Acc% = 0.42578125\n",
      " batch 750: loss = 1.1651470605532328, Acc% = 0.5\n",
      " batch 1500: loss = 1.1683583249251048, Acc% = 0.53125\n",
      "Last train (avg batch) loss = 1.1683583249251048, Avg Val Loss = 1.209749698638916, Val Acc% = 0.49477572114709434\n",
      "######## Epoch 44: ############\n",
      " batch 0: loss = 0.0015734453201293945, Acc% = 0.5390625\n",
      " batch 750: loss = 1.1639296123186746, Acc% = 0.47265625\n",
      " batch 1500: loss = 1.1664349582195281, Acc% = 0.56640625\n",
      "Last train (avg batch) loss = 1.1664349582195281, Avg Val Loss = 1.2194303274154663, Val Acc% = 0.493216863747437\n",
      "######## Epoch 45: ############\n",
      " batch 0: loss = 0.0013567908604939778, Acc% = 0.52734375\n",
      " batch 750: loss = 1.1619076759020488, Acc% = 0.50390625\n",
      " batch 1500: loss = 1.1683920477231344, Acc% = 0.5\n",
      "Last train (avg batch) loss = 1.1683920477231344, Avg Val Loss = 1.2052764892578125, Val Acc% = 0.4950285088335253\n",
      "######## Epoch 46: ############\n",
      " batch 0: loss = 0.001553458054860433, Acc% = 0.4921875\n",
      " batch 750: loss = 1.16031663107872, Acc% = 0.49609375\n",
      " batch 1500: loss = 1.1640011117458344, Acc% = 0.46875\n",
      "Last train (avg batch) loss = 1.1640011117458344, Avg Val Loss = 1.2172690629959106, Val Acc% = 0.493989270567087\n",
      "######## Epoch 47: ############\n",
      " batch 0: loss = 0.0015863327980041504, Acc% = 0.46484375\n",
      " batch 750: loss = 1.1581751182874043, Acc% = 0.53125\n",
      " batch 1500: loss = 1.162707596540451, Acc% = 0.4609375\n",
      "Last train (avg batch) loss = 1.162707596540451, Avg Val Loss = 1.212741494178772, Val Acc% = 0.4952251214785271\n",
      "######## Epoch 48: ############\n",
      " batch 0: loss = 0.001561261494954427, Acc% = 0.45703125\n",
      " batch 750: loss = 1.1605706491470338, Acc% = 0.50390625\n",
      " batch 1500: loss = 1.1622428580919901, Acc% = 0.53125\n",
      "Last train (avg batch) loss = 1.1622428580919901, Avg Val Loss = 1.215381383895874, Val Acc% = 0.49228997556385695\n",
      "######## Epoch 49: ############\n",
      " batch 0: loss = 0.0014986178080240884, Acc% = 0.546875\n",
      " batch 750: loss = 1.158072654803594, Acc% = 0.5390625\n",
      " batch 1500: loss = 1.159948435306549, Acc% = 0.515625\n",
      "Last train (avg batch) loss = 1.159948435306549, Avg Val Loss = 1.2191590070724487, Val Acc% = 0.49105412465241693\n",
      "######## Epoch 50: ############\n",
      " batch 0: loss = 0.0015858337084452311, Acc% = 0.5078125\n",
      " batch 750: loss = 1.1572609108289083, Acc% = 0.515625\n",
      " batch 1500: loss = 1.1575486083030702, Acc% = 0.51953125\n",
      "Last train (avg batch) loss = 1.1575486083030702, Avg Val Loss = 1.2094963788986206, Val Acc% = 0.49240232564671516\n",
      "######## Epoch 51: ############\n",
      " batch 0: loss = 0.0015063589413960774, Acc% = 0.4921875\n",
      " batch 750: loss = 1.1572672306696574, Acc% = 0.53515625\n",
      " batch 1500: loss = 1.1577764166196187, Acc% = 0.5234375\n",
      "Last train (avg batch) loss = 1.1577764166196187, Avg Val Loss = 1.2112884521484375, Val Acc% = 0.4917563126702806\n",
      "######## Epoch 52: ############\n",
      " batch 0: loss = 0.001379909833272298, Acc% = 0.51953125\n",
      " batch 750: loss = 1.1560390895207724, Acc% = 0.49609375\n",
      " batch 1500: loss = 1.1575293299357097, Acc% = 0.4921875\n",
      "Last train (avg batch) loss = 1.1575293299357097, Avg Val Loss = 1.211127758026123, Val Acc% = 0.4942841895345898\n",
      "######## Epoch 53: ############\n",
      " batch 0: loss = 0.0016097140312194824, Acc% = 0.43359375\n",
      " batch 750: loss = 1.1517350571950278, Acc% = 0.51953125\n",
      " batch 1500: loss = 1.1607071828047435, Acc% = 0.59765625\n",
      "Last train (avg batch) loss = 1.1607071828047435, Avg Val Loss = 1.2086511850357056, Val Acc% = 0.4960817908603208\n",
      "######## Epoch 54: ############\n",
      " batch 0: loss = 0.0015534777641296386, Acc% = 0.5\n",
      " batch 750: loss = 1.15279909769694, Acc% = 0.46875\n",
      " batch 1500: loss = 1.1567429083188374, Acc% = 0.5234375\n",
      "Last train (avg batch) loss = 1.1567429083188374, Avg Val Loss = 1.2181919813156128, Val Acc% = 0.49366626407886977\n",
      "######## Epoch 55: ############\n",
      " batch 0: loss = 0.0014773888587951661, Acc% = 0.53125\n",
      " batch 750: loss = 1.1492168951034545, Acc% = 0.57421875\n",
      " batch 1500: loss = 1.1558388231595358, Acc% = 0.5234375\n",
      "Last train (avg batch) loss = 1.1558388231595358, Avg Val Loss = 1.2101761102676392, Val Acc% = 0.49318877622672247\n",
      "######## Epoch 56: ############\n",
      " batch 0: loss = 0.001512874444325765, Acc% = 0.51953125\n",
      " batch 750: loss = 1.1505404850641887, Acc% = 0.453125\n",
      " batch 1500: loss = 1.1563765624364217, Acc% = 0.4921875\n",
      "Last train (avg batch) loss = 1.1563765624364217, Avg Val Loss = 1.2180719375610352, Val Acc% = 0.49162991882706514\n",
      "######## Epoch 57: ############\n",
      " batch 0: loss = 0.0014864322344462077, Acc% = 0.50390625\n",
      " batch 750: loss = 1.1476964209874472, Acc% = 0.515625\n",
      " batch 1500: loss = 1.1512365055878957, Acc% = 0.53515625\n",
      "Last train (avg batch) loss = 1.1512365055878957, Avg Val Loss = 1.2201541662216187, Val Acc% = 0.4922478442827852\n",
      "######## Epoch 58: ############\n",
      " batch 0: loss = 0.0015100242296854655, Acc% = 0.54296875\n",
      " batch 750: loss = 1.1480461566448212, Acc% = 0.53125\n",
      " batch 1500: loss = 1.1509461541175843, Acc% = 0.49609375\n",
      "Last train (avg batch) loss = 1.1509461541175843, Avg Val Loss = 1.226151466369629, Val Acc% = 0.4928095946970761\n",
      "######## Epoch 59: ############\n",
      " batch 0: loss = 0.0016111237208048502, Acc% = 0.50390625\n",
      " batch 750: loss = 1.1478512094815572, Acc% = 0.48046875\n",
      " batch 1500: loss = 1.1504603589375815, Acc% = 0.4921875\n",
      "Last train (avg batch) loss = 1.1504603589375815, Avg Val Loss = 1.2156869173049927, Val Acc% = 0.493062382383507\n",
      "######## Epoch 60: ############\n",
      " batch 0: loss = 0.001486025333404541, Acc% = 0.5234375\n",
      " batch 750: loss = 1.1475693320433298, Acc% = 0.5390625\n",
      " batch 1500: loss = 1.147186346213023, Acc% = 0.54296875\n",
      "Last train (avg batch) loss = 1.147186346213023, Avg Val Loss = 1.2236241102218628, Val Acc% = 0.4942701457742325\n",
      "######## Epoch 61: ############\n",
      " batch 0: loss = 0.0015127566655476889, Acc% = 0.5625\n",
      " batch 750: loss = 1.1461152107715606, Acc% = 0.55078125\n",
      " batch 1500: loss = 1.1511072322527567, Acc% = 0.53515625\n",
      "Last train (avg batch) loss = 1.1511072322527567, Avg Val Loss = 1.2165049314498901, Val Acc% = 0.4923461506052861\n",
      "######## Epoch 62: ############\n",
      " batch 0: loss = 0.0015289727846781412, Acc% = 0.51171875\n",
      " batch 750: loss = 1.1439068716367087, Acc% = 0.515625\n",
      " batch 1500: loss = 1.1492957909107209, Acc% = 0.48046875\n",
      "Last train (avg batch) loss = 1.1492957909107209, Avg Val Loss = 1.2171968221664429, Val Acc% = 0.4922618880431424\n",
      "######## Epoch 63: ############\n",
      " batch 0: loss = 0.0016311556498209635, Acc% = 0.4921875\n",
      " batch 750: loss = 1.143426263252894, Acc% = 0.515625\n",
      " batch 1500: loss = 1.145609190305074, Acc% = 0.43359375\n",
      "Last train (avg batch) loss = 1.145609190305074, Avg Val Loss = 1.2231831550598145, Val Acc% = 0.4926972446142179\n",
      "######## Epoch 64: ############\n",
      " batch 0: loss = 0.0014583743413289388, Acc% = 0.55078125\n",
      " batch 750: loss = 1.143176690419515, Acc% = 0.54296875\n",
      " batch 1500: loss = 1.1443021833101907, Acc% = 0.546875\n",
      "Last train (avg batch) loss = 1.1443021833101907, Avg Val Loss = 1.2193384170532227, Val Acc% = 0.4904502429570542\n",
      "######## Epoch 65: ############\n",
      " batch 0: loss = 0.001512385368347168, Acc% = 0.53125\n",
      " batch 750: loss = 1.1386373870372772, Acc% = 0.55078125\n",
      " batch 1500: loss = 1.1474448059399922, Acc% = 0.4921875\n",
      "Last train (avg batch) loss = 1.1474448059399922, Avg Val Loss = 1.2193430662155151, Val Acc% = 0.4929500323006488\n",
      "######## Epoch 66: ############\n",
      " batch 0: loss = 0.0015580053329467772, Acc% = 0.48828125\n",
      " batch 750: loss = 1.1441252845128378, Acc% = 0.53515625\n",
      " batch 1500: loss = 1.1425065472126008, Acc% = 0.49609375\n",
      "Last train (avg batch) loss = 1.1425065472126008, Avg Val Loss = 1.2223742008209229, Val Acc% = 0.49077324944527145\n",
      "######## Epoch 67: ############\n",
      " batch 0: loss = 0.0015183170636494955, Acc% = 0.51953125\n",
      " batch 750: loss = 1.1406047511895498, Acc% = 0.4921875\n",
      " batch 1500: loss = 1.1439419146378835, Acc% = 0.47265625\n",
      "Last train (avg batch) loss = 1.1439419146378835, Avg Val Loss = 1.222693920135498, Val Acc% = 0.4929359885402915\n",
      "######## Epoch 68: ############\n",
      " batch 0: loss = 0.0015142698287963867, Acc% = 0.515625\n",
      " batch 750: loss = 1.1383936080137889, Acc% = 0.55078125\n",
      " batch 1500: loss = 1.1427582974433899, Acc% = 0.51171875\n",
      "Last train (avg batch) loss = 1.1427582974433899, Avg Val Loss = 1.2199277877807617, Val Acc% = 0.49266915709350334\n",
      "######## Epoch 69: ############\n",
      " batch 0: loss = 0.0014758545557657877, Acc% = 0.4921875\n",
      " batch 750: loss = 1.1378921543757121, Acc% = 0.515625\n",
      " batch 1500: loss = 1.1418932619094848, Acc% = 0.5390625\n",
      "Last train (avg batch) loss = 1.1418932619094848, Avg Val Loss = 1.2249517440795898, Val Acc% = 0.4918124877117097\n",
      "######## Epoch 70: ############\n",
      " batch 0: loss = 0.0014714701970418294, Acc% = 0.5234375\n",
      " batch 750: loss = 1.1388087655703227, Acc% = 0.4765625\n",
      " batch 1500: loss = 1.1390951495170594, Acc% = 0.4765625\n",
      "Last train (avg batch) loss = 1.1390951495170594, Avg Val Loss = 1.2327266931533813, Val Acc% = 0.4888071229952532\n",
      "######## Epoch 71: ############\n",
      " batch 0: loss = 0.0015522586504618328, Acc% = 0.49609375\n",
      " batch 750: loss = 1.1339109336535136, Acc% = 0.5234375\n",
      " batch 1500: loss = 1.139191373904546, Acc% = 0.5\n",
      "Last train (avg batch) loss = 1.139191373904546, Avg Val Loss = 1.2384341955184937, Val Acc% = 0.4837794567873494\n",
      "######## Epoch 72: ############\n",
      " batch 0: loss = 0.0014537949562072755, Acc% = 0.55078125\n",
      " batch 750: loss = 1.1378262337048848, Acc% = 0.484375\n",
      " batch 1500: loss = 1.1360082335472106, Acc% = 0.51171875\n",
      "Last train (avg batch) loss = 1.1360082335472106, Avg Val Loss = 1.2225391864776611, Val Acc% = 0.4900570176670505\n",
      "######## Epoch 73: ############\n",
      " batch 0: loss = 0.0015418103535970052, Acc% = 0.484375\n",
      " batch 750: loss = 1.1342606666088104, Acc% = 0.4765625\n",
      " batch 1500: loss = 1.1380305919647218, Acc% = 0.515625\n",
      "Last train (avg batch) loss = 1.1380305919647218, Avg Val Loss = 1.2258449792861938, Val Acc% = 0.49171418138920875\n",
      "######## Epoch 74: ############\n",
      " batch 0: loss = 0.001500955581665039, Acc% = 0.52734375\n",
      " batch 750: loss = 1.1325558187166849, Acc% = 0.5390625\n",
      " batch 1500: loss = 1.1364591372013093, Acc% = 0.51953125\n",
      "Last train (avg batch) loss = 1.1364591372013093, Avg Val Loss = 1.2372236251831055, Val Acc% = 0.49147543746313516\n",
      "######## Epoch 75: ############\n",
      " batch 0: loss = 0.001432801087697347, Acc% = 0.59375\n",
      " batch 750: loss = 1.1326164283752442, Acc% = 0.54296875\n",
      " batch 1500: loss = 1.1380755313237507, Acc% = 0.5\n",
      "Last train (avg batch) loss = 1.1380755313237507, Avg Val Loss = 1.2326771020889282, Val Acc% = 0.4892986546077578\n",
      "######## Epoch 76: ############\n",
      " batch 0: loss = 0.0014466759363810221, Acc% = 0.5390625\n",
      " batch 750: loss = 1.130452759583791, Acc% = 0.4609375\n",
      " batch 1500: loss = 1.1348896026611328, Acc% = 0.5\n",
      "Last train (avg batch) loss = 1.1348896026611328, Avg Val Loss = 1.2209798097610474, Val Acc% = 0.4933151700699379\n",
      "######## Epoch 77: ############\n",
      " batch 0: loss = 0.0014652504920959473, Acc% = 0.54296875\n",
      " batch 750: loss = 1.1313238496780396, Acc% = 0.51171875\n",
      " batch 1500: loss = 1.1368084104855856, Acc% = 0.5703125\n",
      "Last train (avg batch) loss = 1.1368084104855856, Avg Val Loss = 1.2358043193817139, Val Acc% = 0.4900570176670505\n",
      "######## Epoch 78: ############\n",
      " batch 0: loss = 0.0014923342068990071, Acc% = 0.52734375\n",
      " batch 750: loss = 1.128979989528656, Acc% = 0.5703125\n",
      " batch 1500: loss = 1.1354523587226868, Acc% = 0.47265625\n",
      "Last train (avg batch) loss = 1.1354523587226868, Avg Val Loss = 1.2261813879013062, Val Acc% = 0.4907592056849142\n",
      "######## Epoch 79: ############\n",
      " batch 0: loss = 0.001544998009999593, Acc% = 0.5078125\n",
      " batch 750: loss = 1.130713126818339, Acc% = 0.5234375\n",
      " batch 1500: loss = 1.1311981406211853, Acc% = 0.4921875\n",
      "Last train (avg batch) loss = 1.1311981406211853, Avg Val Loss = 1.2305569648742676, Val Acc% = 0.49209336291885514\n",
      "######## Epoch 80: ############\n",
      " batch 0: loss = 0.001361785093943278, Acc% = 0.5859375\n",
      " batch 750: loss = 1.129420035123825, Acc% = 0.44921875\n",
      " batch 1500: loss = 1.130998805920283, Acc% = 0.55078125\n",
      "Last train (avg batch) loss = 1.130998805920283, Avg Val Loss = 1.2375168800354004, Val Acc% = 0.49345560767351065\n",
      "######## Epoch 81: ############\n",
      " batch 0: loss = 0.0014940878550211588, Acc% = 0.55078125\n",
      " batch 750: loss = 1.1270087618033091, Acc% = 0.515625\n",
      " batch 1500: loss = 1.133625629901886, Acc% = 0.53515625\n",
      "Last train (avg batch) loss = 1.133625629901886, Avg Val Loss = 1.2353299856185913, Val Acc% = 0.49125073729741875\n",
      "######## Epoch 82: ############\n",
      " batch 0: loss = 0.001501511573791504, Acc% = 0.51953125\n",
      " batch 750: loss = 1.1250361615816753, Acc% = 0.50390625\n",
      " batch 1500: loss = 1.1296954463322957, Acc% = 0.54296875\n",
      "Last train (avg batch) loss = 1.1296954463322957, Avg Val Loss = 1.2401007413864136, Val Acc% = 0.4894952672527596\n",
      "######## Epoch 83: ############\n",
      " batch 0: loss = 0.0015119214057922362, Acc% = 0.51953125\n",
      " batch 750: loss = 1.1240514987309773, Acc% = 0.5\n",
      " batch 1500: loss = 1.1291776719093323, Acc% = 0.54296875\n",
      "Last train (avg batch) loss = 1.1291776719093323, Avg Val Loss = 1.2397352457046509, Val Acc% = 0.49019745527062325\n",
      "######## Epoch 84: ############\n",
      " batch 0: loss = 0.0015750945409138998, Acc% = 0.4921875\n",
      " batch 750: loss = 1.1268261008262634, Acc% = 0.546875\n",
      " batch 1500: loss = 1.1270685607592266, Acc% = 0.53125\n",
      "Last train (avg batch) loss = 1.1270685607592266, Avg Val Loss = 1.2470918893814087, Val Acc% = 0.4878661910513159\n",
      "######## Epoch 85: ############\n",
      " batch 0: loss = 0.0014650699297587076, Acc% = 0.55078125\n",
      " batch 750: loss = 1.1254152009487153, Acc% = 0.546875\n",
      " batch 1500: loss = 1.1288277594248455, Acc% = 0.53125\n",
      "Last train (avg batch) loss = 1.1288277594248455, Avg Val Loss = 1.2521395683288574, Val Acc% = 0.49146139370277786\n",
      "######## Epoch 86: ############\n",
      " batch 0: loss = 0.0014377705256144206, Acc% = 0.50390625\n",
      " batch 750: loss = 1.1229269304275513, Acc% = 0.45703125\n",
      " batch 1500: loss = 1.1259972290198008, Acc% = 0.515625\n",
      "Last train (avg batch) loss = 1.1259972290198008, Avg Val Loss = 1.2437505722045898, Val Acc% = 0.486433727494874\n",
      "######## Epoch 87: ############\n",
      " batch 0: loss = 0.0015555952390034994, Acc% = 0.5078125\n",
      " batch 750: loss = 1.120686552842458, Acc% = 0.53125\n",
      " batch 1500: loss = 1.1280066792964936, Acc% = 0.53125\n",
      "Last train (avg batch) loss = 1.1280066792964936, Avg Val Loss = 1.2407524585723877, Val Acc% = 0.4894812234924023\n",
      "######## Epoch 88: ############\n",
      " batch 0: loss = 0.0015127366383870442, Acc% = 0.484375\n",
      " batch 750: loss = 1.120488684654236, Acc% = 0.5078125\n",
      " batch 1500: loss = 1.1283490739663442, Acc% = 0.58984375\n",
      "Last train (avg batch) loss = 1.1283490739663442, Avg Val Loss = 1.2415052652359009, Val Acc% = 0.4908575120074151\n",
      "######## Epoch 89: ############\n",
      " batch 0: loss = 0.0014785693486531575, Acc% = 0.546875\n",
      " batch 750: loss = 1.1214436689217886, Acc% = 0.51953125\n",
      " batch 1500: loss = 1.1252060629526774, Acc% = 0.56640625\n",
      "Last train (avg batch) loss = 1.1252060629526774, Avg Val Loss = 1.2450826168060303, Val Acc% = 0.48830154762239136\n",
      "######## Epoch 90: ############\n",
      " batch 0: loss = 0.0014657373428344726, Acc% = 0.51171875\n",
      " batch 750: loss = 1.119242529551188, Acc% = 0.5234375\n",
      " batch 1500: loss = 1.122915030479431, Acc% = 0.55859375\n",
      "Last train (avg batch) loss = 1.122915030479431, Avg Val Loss = 1.2409197092056274, Val Acc% = 0.49278150717636154\n",
      "######## Epoch 91: ############\n",
      " batch 0: loss = 0.0015838847160339355, Acc% = 0.48828125\n",
      " batch 750: loss = 1.1194111138184866, Acc% = 0.56640625\n",
      " batch 1500: loss = 1.1223752207756041, Acc% = 0.54296875\n",
      "Last train (avg batch) loss = 1.1223752207756041, Avg Val Loss = 1.250632882118225, Val Acc% = 0.4907311181641996\n",
      "######## Epoch 92: ############\n",
      " batch 0: loss = 0.001484460194905599, Acc% = 0.51953125\n",
      " batch 750: loss = 1.118674613714218, Acc% = 0.5\n",
      " batch 1500: loss = 1.120464617729187, Acc% = 0.53515625\n",
      "Last train (avg batch) loss = 1.120464617729187, Avg Val Loss = 1.2409104108810425, Val Acc% = 0.4913771311406342\n",
      "######## Epoch 93: ############\n",
      " batch 0: loss = 0.0014695118268330891, Acc% = 0.53515625\n",
      " batch 750: loss = 1.1184335549672444, Acc% = 0.5234375\n",
      " batch 1500: loss = 1.1188595929940541, Acc% = 0.44921875\n",
      "Last train (avg batch) loss = 1.1188595929940541, Avg Val Loss = 1.250126838684082, Val Acc% = 0.4873746594388113\n",
      "######## Epoch 94: ############\n",
      " batch 0: loss = 0.0014583651224772136, Acc% = 0.546875\n",
      " batch 750: loss = 1.1200081856250763, Acc% = 0.45703125\n",
      " batch 1500: loss = 1.1217850437164307, Acc% = 0.4453125\n",
      "Last train (avg batch) loss = 1.1217850437164307, Avg Val Loss = 1.2655822038650513, Val Acc% = 0.4857596269977249\n",
      "######## Epoch 95: ############\n",
      " batch 0: loss = 0.0015072232882181803, Acc% = 0.54296875\n",
      " batch 750: loss = 1.1167328000863392, Acc% = 0.515625\n",
      " batch 1500: loss = 1.1195634734630584, Acc% = 0.515625\n",
      "Last train (avg batch) loss = 1.1195634734630584, Avg Val Loss = 1.2526710033416748, Val Acc% = 0.4886526416313232\n",
      "######## Epoch 96: ############\n",
      " batch 0: loss = 0.0013794560432434082, Acc% = 0.56640625\n",
      " batch 750: loss = 1.1134775710105895, Acc% = 0.46875\n",
      " batch 1500: loss = 1.1184554700851441, Acc% = 0.52734375\n",
      "Last train (avg batch) loss = 1.1184554700851441, Avg Val Loss = 1.2537169456481934, Val Acc% = 0.49042215543633966\n",
      "######## Epoch 97: ############\n",
      " batch 0: loss = 0.0014739572207132976, Acc% = 0.5390625\n",
      " batch 750: loss = 1.1144082817236582, Acc% = 0.50390625\n",
      " batch 1500: loss = 1.116844839890798, Acc% = 0.54296875\n",
      "Last train (avg batch) loss = 1.116844839890798, Avg Val Loss = 1.2534573078155518, Val Acc% = 0.4877117096873859\n",
      "######## Epoch 98: ############\n",
      " batch 0: loss = 0.0014683483441670735, Acc% = 0.53515625\n",
      " batch 750: loss = 1.1151595367590585, Acc% = 0.5234375\n",
      " batch 1500: loss = 1.1170024921099344, Acc% = 0.53125\n",
      "Last train (avg batch) loss = 1.1170024921099344, Avg Val Loss = 1.2531598806381226, Val Acc% = 0.48689717158666407\n",
      "######## Epoch 99: ############\n",
      " batch 0: loss = 0.0014267799059549968, Acc% = 0.57421875\n",
      " batch 750: loss = 1.1110645352999369, Acc% = 0.51953125\n",
      " batch 1500: loss = 1.118075739145279, Acc% = 0.53515625\n",
      "Last train (avg batch) loss = 1.118075739145279, Avg Val Loss = 1.2526911497116089, Val Acc% = 0.48578771451843944\n",
      "######## Epoch 100: ############\n",
      " batch 0: loss = 0.001482977867126465, Acc% = 0.53515625\n",
      " batch 750: loss = 1.111881827990214, Acc% = 0.60546875\n",
      " batch 1500: loss = 1.1143045853773752, Acc% = 0.5078125\n",
      "Last train (avg batch) loss = 1.1143045853773752, Avg Val Loss = 1.262988805770874, Val Acc% = 0.4876976659270286\n",
      "######## Epoch 101: ############\n",
      " batch 0: loss = 0.001441629409790039, Acc% = 0.546875\n",
      " batch 750: loss = 1.1113394827047984, Acc% = 0.57421875\n",
      " batch 1500: loss = 1.1144568924109142, Acc% = 0.48828125\n",
      "Last train (avg batch) loss = 1.1144568924109142, Avg Val Loss = 1.2555838823318481, Val Acc% = 0.4877117096873859\n",
      "######## Epoch 102: ############\n",
      " batch 0: loss = 0.0013618000348409017, Acc% = 0.57421875\n",
      " batch 750: loss = 1.1104519267082213, Acc% = 0.5390625\n",
      " batch 1500: loss = 1.1155042262077333, Acc% = 0.4921875\n",
      "Last train (avg batch) loss = 1.1155042262077333, Avg Val Loss = 1.2590316534042358, Val Acc% = 0.48858242282953684\n",
      "######## Epoch 103: ############\n",
      " batch 0: loss = 0.0015088292757670086, Acc% = 0.5625\n",
      " batch 750: loss = 1.112465450445811, Acc% = 0.47265625\n",
      " batch 1500: loss = 1.108875968694687, Acc% = 0.6015625\n",
      "Last train (avg batch) loss = 1.108875968694687, Avg Val Loss = 1.2546706199645996, Val Acc% = 0.4892846108474005\n",
      "######## Epoch 104: ############\n",
      " batch 0: loss = 0.001483698050181071, Acc% = 0.5546875\n",
      " batch 750: loss = 1.1094948177337647, Acc% = 0.4921875\n",
      " batch 1500: loss = 1.1114638379414876, Acc% = 0.58203125\n",
      "Last train (avg batch) loss = 1.1114638379414876, Avg Val Loss = 1.2584198713302612, Val Acc% = 0.48847007274667864\n",
      "######## Epoch 105: ############\n",
      " batch 0: loss = 0.0014907919565836588, Acc% = 0.5546875\n",
      " batch 750: loss = 1.109360979159673, Acc% = 0.5078125\n",
      " batch 1500: loss = 1.1099994633992514, Acc% = 0.51171875\n",
      "Last train (avg batch) loss = 1.1099994633992514, Avg Val Loss = 1.2612196207046509, Val Acc% = 0.4845378198466421\n",
      "######## Epoch 106: ############\n",
      " batch 0: loss = 0.0013858540852864584, Acc% = 0.578125\n",
      " batch 750: loss = 1.1052986971537273, Acc% = 0.53515625\n",
      " batch 1500: loss = 1.111943452278773, Acc% = 0.484375\n",
      "Last train (avg batch) loss = 1.111943452278773, Avg Val Loss = 1.2655051946640015, Val Acc% = 0.4802544729376738\n",
      "######## Epoch 107: ############\n",
      " batch 0: loss = 0.0014791626930236816, Acc% = 0.515625\n",
      " batch 750: loss = 1.106786159992218, Acc% = 0.46484375\n",
      " batch 1500: loss = 1.1083940273125967, Acc% = 0.4921875\n",
      "Last train (avg batch) loss = 1.1083940273125967, Avg Val Loss = 1.2646405696868896, Val Acc% = 0.48706569671095135\n",
      "######## Epoch 108: ############\n",
      " batch 0: loss = 0.001356367270151774, Acc% = 0.5546875\n",
      " batch 750: loss = 1.1040359176794687, Acc% = 0.5\n",
      " batch 1500: loss = 1.1116181930700937, Acc% = 0.4921875\n",
      "Last train (avg batch) loss = 1.1116181930700937, Avg Val Loss = 1.2730576992034912, Val Acc% = 0.48772575344774316\n",
      "######## Epoch 109: ############\n",
      " batch 0: loss = 0.0015230838457743327, Acc% = 0.49609375\n",
      " batch 750: loss = 1.1062362392743428, Acc% = 0.52734375\n",
      " batch 1500: loss = 1.1073442873954773, Acc% = 0.4765625\n",
      "Last train (avg batch) loss = 1.1073442873954773, Avg Val Loss = 1.2782618999481201, Val Acc% = 0.4838215880684212\n",
      "######## Epoch 110: ############\n",
      " batch 0: loss = 0.001465537707010905, Acc% = 0.5390625\n",
      " batch 750: loss = 1.101690139691035, Acc% = 0.5390625\n",
      " batch 1500: loss = 1.108927759250005, Acc% = 0.51953125\n",
      "Last train (avg batch) loss = 1.108927759250005, Avg Val Loss = 1.2782020568847656, Val Acc% = 0.4850714827402185\n",
      "######## Epoch 111: ############\n",
      " batch 0: loss = 0.001428585688273112, Acc% = 0.51171875\n",
      " batch 750: loss = 1.1064682912826538, Acc% = 0.52734375\n",
      " batch 1500: loss = 1.1062446343898773, Acc% = 0.55078125\n",
      "Last train (avg batch) loss = 1.1062446343898773, Avg Val Loss = 1.2611184120178223, Val Acc% = 0.48626520237058674\n",
      "######## Epoch 112: ############\n",
      " batch 0: loss = 0.0014855543772379558, Acc% = 0.53125\n",
      " batch 750: loss = 1.100056233962377, Acc% = 0.515625\n",
      " batch 1500: loss = 1.1060168035825093, Acc% = 0.50390625\n",
      "Last train (avg batch) loss = 1.1060168035825093, Avg Val Loss = 1.2826294898986816, Val Acc% = 0.48342836277841755\n",
      "######## Epoch 113: ############\n",
      " batch 0: loss = 0.0015298714637756348, Acc% = 0.53515625\n",
      " batch 750: loss = 1.1039826617240907, Acc% = 0.5234375\n",
      " batch 1500: loss = 1.1070954995950064, Acc% = 0.484375\n",
      "Last train (avg batch) loss = 1.1070954995950064, Avg Val Loss = 1.2673739194869995, Val Acc% = 0.4871780467938095\n",
      "######## Epoch 114: ############\n",
      " batch 0: loss = 0.001363179365793864, Acc% = 0.5703125\n",
      " batch 750: loss = 1.102591776529948, Acc% = 0.53515625\n",
      " batch 1500: loss = 1.1046330309708914, Acc% = 0.54296875\n",
      "Last train (avg batch) loss = 1.1046330309708914, Avg Val Loss = 1.2718948125839233, Val Acc% = 0.4848748700952167\n",
      "######## Epoch 115: ############\n",
      " batch 0: loss = 0.0013648908933003743, Acc% = 0.55859375\n",
      " batch 750: loss = 1.096871919711431, Acc% = 0.546875\n",
      " batch 1500: loss = 1.1049379614988963, Acc% = 0.5078125\n",
      "Last train (avg batch) loss = 1.1049379614988963, Avg Val Loss = 1.2723710536956787, Val Acc% = 0.4847063449709294\n",
      "######## Epoch 116: ############\n",
      " batch 0: loss = 0.0014457135200500488, Acc% = 0.55859375\n",
      " batch 750: loss = 1.0990970562299092, Acc% = 0.52734375\n",
      " batch 1500: loss = 1.1066732773780823, Acc% = 0.51953125\n",
      "Last train (avg batch) loss = 1.1066732773780823, Avg Val Loss = 1.2890297174453735, Val Acc% = 0.48821728506024775\n",
      "######## Epoch 117: ############\n",
      " batch 0: loss = 0.001554567337036133, Acc% = 0.4765625\n",
      " batch 750: loss = 1.096402690966924, Acc% = 0.5078125\n",
      " batch 1500: loss = 1.1066798077424367, Acc% = 0.53515625\n",
      "Last train (avg batch) loss = 1.1066798077424367, Avg Val Loss = 1.2758296728134155, Val Acc% = 0.488076847456675\n",
      "######## Epoch 118: ############\n",
      " batch 0: loss = 0.0014269507726033528, Acc% = 0.5390625\n",
      " batch 750: loss = 1.1007226569652557, Acc% = 0.53125\n",
      " batch 1500: loss = 1.0981354570388795, Acc% = 0.52734375\n",
      "Last train (avg batch) loss = 1.0981354570388795, Avg Val Loss = 1.2813702821731567, Val Acc% = 0.486995477909165\n",
      "######## Epoch 119: ############\n",
      " batch 0: loss = 0.0015255711873372396, Acc% = 0.49609375\n",
      " batch 750: loss = 1.0991194821198782, Acc% = 0.546875\n",
      " batch 1500: loss = 1.099103626171748, Acc% = 0.5\n",
      "Last train (avg batch) loss = 1.099103626171748, Avg Val Loss = 1.289908528327942, Val Acc% = 0.4871920905541668\n",
      "######## Epoch 120: ############\n",
      " batch 0: loss = 0.0014119431177775064, Acc% = 0.54296875\n",
      " batch 750: loss = 1.0997897696495056, Acc% = 0.48828125\n",
      " batch 1500: loss = 1.1003547030289969, Acc% = 0.5703125\n",
      "Last train (avg batch) loss = 1.1003547030289969, Avg Val Loss = 1.2748494148254395, Val Acc% = 0.4854085329887931\n",
      "######## Epoch 121: ############\n",
      " batch 0: loss = 0.0015177241961161297, Acc% = 0.546875\n",
      " batch 750: loss = 1.0948462047576903, Acc% = 0.51171875\n",
      " batch 1500: loss = 1.101615917444229, Acc% = 0.54296875\n",
      "Last train (avg batch) loss = 1.101615917444229, Avg Val Loss = 1.2844784259796143, Val Acc% = 0.48685504030559223\n",
      "######## Epoch 122: ############\n",
      " batch 0: loss = 0.0015015864372253417, Acc% = 0.5078125\n",
      " batch 750: loss = 1.0950512643655141, Acc% = 0.54296875\n",
      " batch 1500: loss = 1.1029843575954437, Acc% = 0.54296875\n",
      "Last train (avg batch) loss = 1.1029843575954437, Avg Val Loss = 1.2850148677825928, Val Acc% = 0.4853944892284358\n",
      "######## Epoch 123: ############\n",
      " batch 0: loss = 0.001588311513264974, Acc% = 0.48046875\n",
      " batch 750: loss = 1.0950012010733285, Acc% = 0.5234375\n",
      " batch 1500: loss = 1.0986749278704326, Acc% = 0.52734375\n",
      "Last train (avg batch) loss = 1.0986749278704326, Avg Val Loss = 1.2905696630477905, Val Acc% = 0.4852400078645058\n",
      "######## Epoch 124: ############\n",
      " batch 0: loss = 0.0014291868209838868, Acc% = 0.5546875\n",
      " batch 750: loss = 1.0973331090609233, Acc% = 0.55859375\n",
      " batch 1500: loss = 1.098048220316569, Acc% = 0.5703125\n",
      "Last train (avg batch) loss = 1.098048220316569, Avg Val Loss = 1.2935863733291626, Val Acc% = 0.4863354211723731\n",
      "######## Epoch 125: ############\n",
      " batch 0: loss = 0.0014431899388631184, Acc% = 0.53515625\n",
      " batch 750: loss = 1.0935648169517518, Acc% = 0.5625\n",
      " batch 1500: loss = 1.096375239690145, Acc% = 0.48046875\n",
      "Last train (avg batch) loss = 1.096375239690145, Avg Val Loss = 1.2856415510177612, Val Acc% = 0.4851838328230767\n",
      "######## Epoch 126: ############\n",
      " batch 0: loss = 0.001574106216430664, Acc% = 0.48828125\n",
      " batch 750: loss = 1.089177388270696, Acc% = 0.55859375\n",
      " batch 1500: loss = 1.0976103080908457, Acc% = 0.51171875\n",
      "Last train (avg batch) loss = 1.0976103080908457, Avg Val Loss = 1.290155053138733, Val Acc% = 0.48570345195629583\n",
      "######## Epoch 127: ############\n",
      " batch 0: loss = 0.001547076384226481, Acc% = 0.4921875\n",
      " batch 750: loss = 1.09061048523585, Acc% = 0.56640625\n",
      " batch 1500: loss = 1.0978373653093974, Acc% = 0.515625\n",
      "Last train (avg batch) loss = 1.0978373653093974, Avg Val Loss = 1.2920212745666504, Val Acc% = 0.48521192034379124\n",
      "######## Epoch 128: ############\n",
      " batch 0: loss = 0.001430138905843099, Acc% = 0.5\n",
      " batch 750: loss = 1.0920596617857614, Acc% = 0.53125\n",
      " batch 1500: loss = 1.093297459602356, Acc% = 0.55078125\n",
      "Last train (avg batch) loss = 1.093297459602356, Avg Val Loss = 1.2917900085449219, Val Acc% = 0.48274021852091115\n",
      "######## Epoch 129: ############\n",
      " batch 0: loss = 0.0014353342056274414, Acc% = 0.55859375\n",
      " batch 750: loss = 1.0891643729209899, Acc% = 0.56640625\n",
      " batch 1500: loss = 1.0975028804937998, Acc% = 0.53515625\n",
      "Last train (avg batch) loss = 1.0975028804937998, Avg Val Loss = 1.3026684522628784, Val Acc% = 0.48122349240232565\n",
      "######## Epoch 130: ############\n",
      " batch 0: loss = 0.0013912922541300455, Acc% = 0.5546875\n",
      " batch 750: loss = 1.0888287467161815, Acc% = 0.4921875\n",
      " batch 1500: loss = 1.092262819925944, Acc% = 0.5703125\n",
      "Last train (avg batch) loss = 1.092262819925944, Avg Val Loss = 1.3007476329803467, Val Acc% = 0.48626520237058674\n",
      "######## Epoch 131: ############\n",
      " batch 0: loss = 0.0015074979464213053, Acc% = 0.5390625\n",
      " batch 750: loss = 1.0885318711598715, Acc% = 0.5\n",
      " batch 1500: loss = 1.0940766667524973, Acc% = 0.53515625\n",
      "Last train (avg batch) loss = 1.0940766667524973, Avg Val Loss = 1.3055146932601929, Val Acc% = 0.48639159621380224\n",
      "######## Epoch 132: ############\n",
      " batch 0: loss = 0.0014539217948913573, Acc% = 0.52734375\n",
      " batch 750: loss = 1.0829383029143016, Acc% = 0.60546875\n",
      " batch 1500: loss = 1.0967607707977296, Acc% = 0.58984375\n",
      "Last train (avg batch) loss = 1.0967607707977296, Avg Val Loss = 1.2941125631332397, Val Acc% = 0.4833721877369885\n",
      "######## Epoch 133: ############\n",
      " batch 0: loss = 0.0015527655283610025, Acc% = 0.47265625\n",
      " batch 750: loss = 1.087404284397761, Acc% = 0.5078125\n",
      " batch 1500: loss = 1.0899499490261078, Acc% = 0.5546875\n",
      "Last train (avg batch) loss = 1.0899499490261078, Avg Val Loss = 1.298812985420227, Val Acc% = 0.4840322444737803\n",
      "######## Epoch 134: ############\n",
      " batch 0: loss = 0.0014708005587259927, Acc% = 0.5390625\n",
      " batch 750: loss = 1.0865323931376138, Acc% = 0.51953125\n",
      " batch 1500: loss = 1.0931672410964965, Acc% = 0.546875\n",
      "Last train (avg batch) loss = 1.0931672410964965, Avg Val Loss = 1.3121397495269775, Val Acc% = 0.4809004859141084\n",
      "######## Epoch 135: ############\n",
      " batch 0: loss = 0.0014265157381693522, Acc% = 0.51953125\n",
      " batch 750: loss = 1.08287806224823, Acc% = 0.51171875\n",
      " batch 1500: loss = 1.0897712062199911, Acc% = 0.5234375\n",
      "Last train (avg batch) loss = 1.0897712062199911, Avg Val Loss = 1.3070313930511475, Val Acc% = 0.48248743083448026\n",
      "######## Epoch 136: ############\n",
      " batch 0: loss = 0.0013050087292989095, Acc% = 0.61328125\n",
      " batch 750: loss = 1.0851025057633719, Acc% = 0.52734375\n",
      " batch 1500: loss = 1.0859969044526419, Acc% = 0.52734375\n",
      "Last train (avg batch) loss = 1.0859969044526419, Avg Val Loss = 1.298148274421692, Val Acc% = 0.4847063449709294\n",
      "######## Epoch 137: ############\n",
      " batch 0: loss = 0.0014409691492716472, Acc% = 0.52734375\n",
      " batch 750: loss = 1.082745614608129, Acc% = 0.61328125\n",
      " batch 1500: loss = 1.0906897404193878, Acc% = 0.5\n",
      "Last train (avg batch) loss = 1.0906897404193878, Avg Val Loss = 1.3048217296600342, Val Acc% = 0.4859562396427267\n",
      "######## Epoch 138: ############\n",
      " batch 0: loss = 0.0014105267524719238, Acc% = 0.55859375\n",
      " batch 750: loss = 1.083343684196472, Acc% = 0.5859375\n",
      " batch 1500: loss = 1.0897157406806945, Acc% = 0.53515625\n",
      "Last train (avg batch) loss = 1.0897157406806945, Avg Val Loss = 1.3045752048492432, Val Acc% = 0.48054939190517654\n",
      "######## Epoch 139: ############\n",
      " batch 0: loss = 0.0015687238375345866, Acc% = 0.5390625\n",
      " batch 750: loss = 1.0850899271170298, Acc% = 0.4921875\n",
      " batch 1500: loss = 1.0875533579985301, Acc% = 0.52734375\n",
      "Last train (avg batch) loss = 1.0875533579985301, Avg Val Loss = 1.3030933141708374, Val Acc% = 0.48578771451843944\n",
      "######## Epoch 140: ############\n",
      " batch 0: loss = 0.0014421757062276204, Acc% = 0.5546875\n",
      " batch 750: loss = 1.0790167285601298, Acc% = 0.546875\n",
      " batch 1500: loss = 1.0906906282107036, Acc% = 0.53125\n",
      "Last train (avg batch) loss = 1.0906906282107036, Avg Val Loss = 1.3147575855255127, Val Acc% = 0.48591410836165494\n",
      "######## Epoch 141: ############\n",
      " batch 0: loss = 0.0015133926073710123, Acc% = 0.53125\n",
      " batch 750: loss = 1.081841956615448, Acc% = 0.546875\n",
      " batch 1500: loss = 1.0864678393205007, Acc% = 0.578125\n",
      "Last train (avg batch) loss = 1.0864678393205007, Avg Val Loss = 1.333522081375122, Val Acc% = 0.48293683116591296\n",
      "######## Epoch 142: ############\n",
      " batch 0: loss = 0.0015186643600463867, Acc% = 0.5390625\n",
      " batch 750: loss = 1.0801004312833151, Acc% = 0.5390625\n",
      " batch 1500: loss = 1.0881862024466196, Acc% = 0.59375\n",
      "Last train (avg batch) loss = 1.0881862024466196, Avg Val Loss = 1.3148531913757324, Val Acc% = 0.48151841136982837\n",
      "######## Epoch 143: ############\n",
      " batch 0: loss = 0.0013143749237060547, Acc% = 0.56640625\n",
      " batch 750: loss = 1.0768849161465963, Acc% = 0.48828125\n",
      " batch 1500: loss = 1.084723843018214, Acc% = 0.54296875\n",
      "Last train (avg batch) loss = 1.084723843018214, Avg Val Loss = 1.3011176586151123, Val Acc% = 0.48362497542341937\n",
      "######## Epoch 144: ############\n",
      " batch 0: loss = 0.0014938165346781412, Acc% = 0.52734375\n",
      " batch 750: loss = 1.0783019608656566, Acc% = 0.5390625\n",
      " batch 1500: loss = 1.0846034362316133, Acc% = 0.5625\n",
      "Last train (avg batch) loss = 1.0846034362316133, Avg Val Loss = 1.3324146270751953, Val Acc% = 0.4822908181894784\n",
      "######## Epoch 145: ############\n",
      " batch 0: loss = 0.0015087588628133139, Acc% = 0.48828125\n",
      " batch 750: loss = 1.0797786724567413, Acc% = 0.515625\n",
      " batch 1500: loss = 1.0815851266384124, Acc% = 0.5625\n",
      "Last train (avg batch) loss = 1.0815851266384124, Avg Val Loss = 1.315673828125, Val Acc% = 0.4817290677751875\n",
      "######## Epoch 146: ############\n",
      " batch 0: loss = 0.0015161110560099284, Acc% = 0.50390625\n",
      " batch 750: loss = 1.0806306184132894, Acc% = 0.49609375\n",
      " batch 1500: loss = 1.0807049273649851, Acc% = 0.50390625\n",
      "Last train (avg batch) loss = 1.0807049273649851, Avg Val Loss = 1.3135396242141724, Val Acc% = 0.4838356318287785\n",
      "######## Epoch 147: ############\n",
      " batch 0: loss = 0.001308486779530843, Acc% = 0.609375\n",
      " batch 750: loss = 1.0742888244787852, Acc% = 0.5\n",
      " batch 1500: loss = 1.083661803007126, Acc% = 0.57421875\n",
      "Last train (avg batch) loss = 1.083661803007126, Avg Val Loss = 1.3173232078552246, Val Acc% = 0.48101283599696654\n",
      "######## Epoch 148: ############\n",
      " batch 0: loss = 0.0013634277979532878, Acc% = 0.546875\n",
      " batch 750: loss = 1.0766202445030213, Acc% = 0.58203125\n",
      " batch 1500: loss = 1.0808749500910442, Acc% = 0.546875\n",
      "Last train (avg batch) loss = 1.0808749500910442, Avg Val Loss = 1.329584002494812, Val Acc% = 0.4801280790944583\n",
      "######## Epoch 149: ############\n",
      " batch 0: loss = 0.00135980224609375, Acc% = 0.58984375\n",
      " batch 750: loss = 1.0762350829442342, Acc% = 0.546875\n",
      " batch 1500: loss = 1.080948633035024, Acc% = 0.5\n",
      "Last train (avg batch) loss = 1.080948633035024, Avg Val Loss = 1.3326425552368164, Val Acc% = 0.4839760694323512\n"
     ]
    }
   ],
   "source": [
    "train_loss_hist, val_loss_hist = train_model(NUM_EPOCHS, train_loss_hist, val_loss_hist, model, optimizer, criterion, training_generator, validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at 300 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f'models/nn_single_model/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(val_loss_hist[100:]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(train_loss_hist[100:]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4904639428820396"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test_generator, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swish_bb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
